%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%% ICML 2016 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Use the following line _only_ if you're still using LaTeX 2.09.
%\documentstyle[icml2016,epsf,natbib]{article}
% If you rely on Latex2e packages, like most moden people use this:
\documentclass{article}

% use Times
\usepackage{times}
% For figures
\usepackage{graphicx} % more modern
%\usepackage{epsfig} % less modern
\usepackage{subfigure} 

% For citations
\usepackage{natbib}

% For algorithms
\usepackage{algorithm}
\usepackage{algorithmic}

% As of 2011, we use the hyperref package to produce hyperlinks in the
% resulting PDF.  If this breaks your system, please commend out the
% following usepackage line and replace \usepackage{icml2016} with
% \usepackage[nohyperref]{icml2016} above.
\usepackage{hyperref}

% Packages hyperref and algorithmic misbehave sometimes.  We can fix
% this with the following command.
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Employ the following version of the ``usepackage'' statement for
% submitting the draft version of the paper for review.  This will set
% the note in the first column to ``Under review.  Do not distribute.''
\usepackage{icml2016} 

% Employ this version of the ``usepackage'' statement after the paper has
% been accepted, when creating the final version.  This will set the
% note in the first column to ``Proceedings of the...''
%\usepackage[accepted]{icml2016}

\usepackage{xargs}                      % Use more than one optional parameter in a new commands
\usepackage[pdftex,dvipsnames]{xcolor}  % Coloured text etc.
% 
\usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}
\newcommandx{\unsure}[2][1=]{\todo[linecolor=red,backgroundcolor=red!25,bordercolor=red,#1]{#2}}
\newcommandx{\change}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=blue,#1]{#2}}
\newcommandx{\info}[2][1=]{\todo[linecolor=OliveGreen,backgroundcolor=OliveGreen!25,bordercolor=OliveGreen,#1]{#2}}
\newcommandx{\improvement}[2][1=]{\todo[linecolor=Plum,backgroundcolor=Plum!25,bordercolor=Plum,#1]{#2}}
\newcommandx{\thiswillnotshow}[2][1=]{\todo[disable,#1]{#2}}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{A Novel Approach to Supervised Classification Using Non-Linear Metrics}

\begin{document} 

\twocolumn[
\icmltitle{A Novel Approach to Supervised Classification Using Non-Linear Metrics}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2016
% package.
\icmlauthor{Krishnan Kumaran, Dimitri Papageorgiou, Francisco Trespalacios}{[krisnan.kumaran,dimitri.j.papageorgiou,francisco.trespalacios]@exxonmobil.com}
\icmladdress{ExxonMobil Corporate Strategic Research,
            1545 US 22 East, Annandale, NJ 08801 USA}
\icmlauthor{Martin Takac, Bolun Xu}{[mat614,bo215]@lehigh.edu}
\icmladdress{Industrial and Systems Eng., Lehigh University
            200 West Packer Avenue, Bethlehem, 18015}

% You may provide any keywords that you 
% find helpful for describing your paper; these are used to populate 
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{boring formatting information, machine learning, ICML}

\vskip 0.3in
]




\begin{abstract} 



\end{abstract} 


\section{Introduction}

\todo[inline,color=red]{This is original abstract,
however, abstract should be just a few lines}



Clustering (also known as unsupervised classification) and Classification (commonly understood to be supervised,
 i.e. based on training data) are common ways of performing data analysis to achieve a range of objectives like 
anomaly detection and diagnosis, data segmentation and model development/refinement. Consequently, there is a 
large body of research on these topics (see for example\cite{Hastie} and references therein for a survey of 
currently used methods) offering different solutions ranging from K-means, spectral methods and other more 
complex methods for Clustering, and Support Vector Machines (SVM), Artificial(Deep/Shallow) Neural Networks (ANN), their 
non-linear Kernel-based variants and others for Classification.

In previous work, we developed clustering methods [see 2012 US patent \cite{KKpatent}] which  extend an existing 
technique known as Agglomerative Clustering using a trade-off curve to automatically select the optimal 
number of clusters in a consistent manner from the data, a capability not available among other commonly 
used clustering algorithms like K-means. Like all clustering methods, however, this method requires the 
choice of a similarity/distance metric between the data points, and while there are typically a few 
reasonable choices for most data, the results can depend strongly on this choice.

In this work, we extend the concepts behind agglomerative clustering to a supervised classification 
method aimed at learning the optimal distance/similarity metric directly from training data. The main advantages of
this form of Supervised Classification, as compared to current state-of-the-art methods (Deep Neural Networks, SVM etc.) are
\begin{itemize}
\item{The formulation accommodates multiple disjoint ``islands'' belonging to the same user-specified class, since
the classification criterion is based on distances to nearest co-class/non-class neighbors. This is a crucial property
to enable accurate classification while allowing for sufficiently simple metrics that do not require all examples of each
class to be forced into a single compact region of the transformed space defined by the metric. It also automatically builds
robustness of classification performance to substantial diversity within user-defined classes, which is often a reality in most practical applications.}
\item{Another key advantage of our method is that the mis-classifications with the optimally computed metric provide guidelines
for new data acquisition and data quality control to improve classification performance. This is a key ``value-of-information'' criterion that can significantly improve both classification performance and computational burden by ensuring training data completeness, representativeness and economy, which are not adequately addressed in current applications of DNN and other methods which often depend on
very large quantities of training data (e.g. internet cat images).}
\end{itemize}

Finally, the metric learning process can be formulated as an optimization problem (Mixed-Integer Linear Program, or MILP, 
in its simplest form) that can be hard to solve for realistic data sizes, but we present fast and parallelizable methods to compute the optimal metric.
We demonstrate classification and computational performance of the algorithms through several simple and intuitive examples.


\section{Introduction}  
Supervised Classification is one of the most commonly used Machine Learning paradigms both in the industry and academic research. There is a large body of past and continuing research on the topic




\todo[inline,color=green]{Explain very clearly what we want to do and why it is important.


mention 

-clustering

-better NN search

-outlier detection

-where to sample new data




}



\paragraph{Brief Literature Review.}


\cite{weinberger2005distance}



\cite{xing2003distance}




\cite{weinberger2009distance}



\cite{yang2006efficient}

\cite{ying2012distance}


\cite{schultz2004learning}

\cite{rosales2006learning}



 
\paragraph{Our Contributions.} 
 
 
 
 
 
 
\section{Motivation \& Illustration Examples}
 
 
 


\section{Mathematical Formulation} 
 
 
\section{Algorithm / Work Flow}



\section{Numerical Experiments/Results}


\subsection{NN comparison}

\subsection{Economy of data collection}

DNN - > autoencoders


\section{Conclusion} 
 
 
% Acknowledgements should only appear in the accepted version. 

% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
%\nocite{langley00}

\bibliography{example_paper}
\bibliographystyle{icml2016}

\end{document} 

\section*{Acknowledgements} 
 
\textbf{Do not} include acknowledgements in the initial version of
the paper submitted for blind review.

If a paper is accepted, the final camera-ready version can (and
probably should) include acknowledgements. In this case, please
place such acknowledgements in an unnumbered section at the
end of the paper. Typically, this will include thanks to reviewers
who gave useful comments, to colleagues who contributed to the ideas, 
and to funding agencies and corporate sponsors that provided financial 
support.  




% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was
% created by Lise Getoor and Tobias Scheffer, it was slightly modified  
% from the 2010 version by Thorsten Joachims & Johannes Fuernkranz, 
% slightly modified from the 2009 version by Kiri Wagstaff and 
% Sam Roweis's 2008 version, which is slightly modified from 
% Prasad Tadepalli's 2007 version which is a lightly 
% changed version of the previous year's version by Andrew Moore, 
% which was in turn edited from those of Kristian Kersting and 
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.  
