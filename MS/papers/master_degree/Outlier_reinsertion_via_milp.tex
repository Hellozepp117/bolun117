\documentclass[]{article}

\renewcommand{\baselinestretch}{1.2}
\renewcommand{\v}[1]{\ensuremath{\mathbf{#1}}}
\newcommand{\mc}{\mathcal}

\def\st{{\rm s.t.}}

\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage[usenames,dvipsnames]{color}
\usepackage{fullpage,graphicx,amssymb,amsmath}
\usepackage{enumerate}
\usepackage{subfigure}


\newcommand{\be}{\begin{enumerate}}
\newcommand{\ee}{\end{enumerate}}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{assumption}{Assumption}
\newtheorem{conjecture}{Conjecture}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newcommand{\hs}[1]{\hspace{#1}}
\newcommand{\vs}[1]{\vspace{#1}}
\newcommand{\mnorm}[1]{||{#1}||_{\infty}}
\newcommand{\pf}{\textbf{Proof} \indent}
\newcommand{\qed}{\hfill $\Box$}
\newcommand{\argmin}{\rm argmin}
\newcommand{\proof}{\pf}

\newcommand{\Cvar}{\mathbb{CVAR}} % Conditional value-at-risk
%\newcommand{\Cvar}{\mathbb{CV}@\mathbb{R}} % Conditional value-at-risk
\newcommand{\Var}{\mathbb{VAR}} % Value-at-risk
%\newcommand{\Var}{\mathbb{V}\text{a}\mathbb{R}} % Value-at-risk
%\newcommand{\Var}{\mathbb{V}@\mathbb{R}} % Value-at-risk

\newcommand{\cone}{{\rm cone}} % Cone
\newcommand{\conv}{{\rm conv}} % Convex hull
\newcommand{\clconv}{{\rm clconv}} % Closed convex hull
\newcommand{\Cov}{{\rm Cov}} % Covariance
\newcommand{\D}{\mathbb{D}} % Distance metric
\newcommand{\E}{\mathbb{E}} % Expectation
\renewcommand{\P}{\mathbb{P}} % Probability
\renewcommand{\Re}{\mathbb{R}} % Real numbers
\renewcommand{\S}{\mathcal{S}} % Set of scenarios
\newcommand{\Z}{\mathbb{Z}} % Integers

\newcommand{\vell}{\boldsymbol{\ell}}
\newcommand{\valpha}{\boldsymbol{\alpha}}
\newcommand{\vbeta}{\boldsymbol{\beta}}
\newcommand{\vgamma}{\boldsymbol{\gamma}}
\newcommand{\vGamma}{\boldsymbol{\Gamma}}
\newcommand{\vdelta}{\boldsymbol{\delta}}
\newcommand{\vlambda}{\boldsymbol{\lambda}}
\newcommand{\vLambda}{\boldsymbol{\Lambda}}
\newcommand{\vxi}{\boldsymbol{\xi}}
\newcommand{\vpi}{\boldsymbol{\pi}}

\newcommand{\xor}{\underline{\vee}}
\newcommand{\Xor}{\underline{\bigvee}}


\title{Outlier re-insertion via Mixed-Integer Linear Programming}
\author{Dimitri J. Papageorgiou \\
{\small Corporate Strategic Research}\\
{\small ExxonMobil Research and Engineering Company}\\
{\small 1545 Route 22 East, Annandale, NJ 08801 USA}\\
{\small dimitri.j.papageorgiou@exxonmobil.com} \\
}

\begin{document}

\maketitle



\section{Outlier re-insertion}

We assume that the distance metric $d_{ij}$ is fixed for the remainder of this section.
Let $\mc{N}$ be the set of all points, 
$\mc{C}_i$ the set of co-class neighbors of point $i$, 
$\bar{\mc{C}}_i$ the set of non co-class neighbors of point $i$, and 
$\mc{O}$ the current set of outliers. 
Let $\mc{IK} = \{ (i,k) \in \mc{N} \times \mc{N} : \nexists~j \in \mc{C}_i \backslash \mc{O}: d_{ij} + \epsilon \leq d_{ik}, k \in \bar{\mc{C}}_i \}$.
Set $M_{ik} = 1 - d_{ik}$. (We are making use of our normalization $d_{ij} \in [0,1]$ here.)
For any outlier penalty parameter $\rho > 0$ (I suggest $\rho = 1$),
the following mixed-integer linear program attempts to minimize the number of outliers given a fixed distance metric.
\begin{subequations} \label{model:milp_outlier_reinsertion}
\begin{alignat}{4}
\min_{\v{y},\v{z}}~~& \rho \sum_{i \in \mc{O}} z_i & & \\
\st~~& \sum_{j \in \mc{C}_i} d_{ij}y_{ij} + \epsilon \leq d_{ik} + M_{ik} z_k && \qquad \forall (i,k) \in \mc{IK} \label{eq:bigM_constraint_reinsertion} \\
    & \sum_{j \in \mc{C}_i} y_{ij} = 1 && \qquad \forall i \in \mc{N} \backslash \mc{O}, j \in \mc{C}_i \label{eq:bigM_select_exactly_one_neighbor_1} \\
    & \sum_{j \in \mc{C}_i} y_{ij} = 1 - z_i && \qquad \forall i \in \mc{O}, j \in \mc{C}_i \label{eq:bigM_select_exactly_one_neighbor_2} \\
    & y_{ij} \leq 1 - z_j && \qquad \forall i \in \mc{N}, j \in \mc{C}_i \cap \mc{O} \\
    & y_{ij} \in \{0,1\} && \qquad \forall i \in \mc{N}, j \in \mc{C}_i \\
    & z_{i} \in \{0,1\} && \qquad \forall i \in \mc{O} \\
    & z_{i} = 0 && \qquad \forall i \in \mc{N} \backslash \mc{O} \label{eq:reinsertion_not_needed_in_aimms}
\end{alignat}
\end{subequations}

Several observations:
\begin{enumerate}
\item Bolun wrote the RHS of constraint~\eqref{eq:bigM_constraint_reinsertion} as $M_i (z_i + z_k)$.  This is correct, but the formulation above is tighter, meaning the linear programming relaxation provides a better lower bound, and thus optimizers believe it will be better.  Why can we replace $M_i (z_i + z_k)$ with $M_{ik} z_k$?  Now that we have constraints~\eqref{eq:bigM_select_exactly_one_neighbor_2}, which effectively set the LHS of \eqref{eq:bigM_constraint_reinsertion} to $\epsilon$ if point $i$ is deemed an outlier ($z_i=1$), there is no reason to include $M_{ik} z_i$ on the RHS of \eqref{eq:bigM_constraint_reinsertion} as well. 
\item What is the set $\mc{IK}$ doing?  What is its purpose?  Given that the distance metric is fixed,
for any pair of points $(i,k): i \in \mc{N}, k \in \bar{\mc{C}}_i$, if 
$$
\min\{ d_{ij} : j \in \mc{C}_i \backslash \mc{O} \} + \epsilon \leq d_{ik}
$$
which holds if and only if 
\begin{equation} \label{eq:reinsertion_existence_condition}
\exists j \in \mc{C}_i \backslash \mc{O} : d_{ij} + \epsilon \leq d_{ik}~,
\end{equation}
then the corresponding constraint~\eqref{eq:bigM_constraint_reinsertion} is already satisfied (and will continue to be satisfied once outliers are considered) and is therefore redundant.
\item Is it really worth the trouble to create the set $\mc{IK}$? Won't the solver take care of this?
While solvers are good at eliminating redundant constraints,
it is best to help them eliminate constraints a priori especially when we can immediately identify them.
This saves the solver time when building the optimization model and in preprocessing. 
Example: Suppose there are 10 classes, 100 points per class, for a total of 1000 points.
For simplicity, suppose there are 3 outliers per class (that is, our algorithm has thus far identified 3 outliers per class so that $|\mc{O}|=30$).
There are 900,000 constraints that must be included if constraints~\eqref{eq:bigM_constraint_reinsertion} are written ``$\forall i \in \mc{N}, k \in \bar{\mc{C}}_i$'' since, for every point $i$ (of which there are 1,000), there are 900 non-neighbors.  However, if we were to replace ``$\forall i \in \mc{N}, k \in \bar{\mc{C}}_i$'' with $\forall (i,k) \in \mc{IK}$, then at least 846,810 (94\%) of the constraints of type \eqref{eq:bigM_constraint_reinsertion} can be eliminated before doing a single optimization. Why? In this example, there are 970 non-outliers, each of which has $9 \times 97$ non-neighbors that are not outliers.  These 846,810 pairs of points have already been shown to satisfy constraints~\eqref{eq:bigM_constraint_reinsertion} to arrive at the current distance metric.  We write ``at least'' because there are likely many other pairs of points involving outliers (i.e., $k \in \mc{O}$) for which the condition \eqref{eq:reinsertion_existence_condition} also holds.  
\end{enumerate}



\subsection{AIMMS implementation}

In AIMMS, there are several items to be aware of.
First, define the set $\mc{IK}$ as follows: 
$$
\mc{IK} = \{ (i,k) | k \in \bar{\mc{C}}_i \texttt{ and not exists}( j \in \mc{C}_i \backslash \mc{O} | d_{ij} + \epsilon \leq d_{ik} ) \}
$$
Second, $z_i$ should only be defined for $i \in \mc{O}$.  You should \textit{not} define it for all $i \in \mc{N}$ and then set $z_i = 0$ for all $i \in \mc{N} \backslash \mc{O}$ as in \eqref{eq:reinsertion_not_needed_in_aimms}. 
Note that AIMMS understands that if $z_i$ appears in a constraint written for all $i \in \mc{N}$, it will only include it when $z_i$ exists.

Third, in summary, the following formulation should be used in AIMMS:
\begin{subequations} \label{model:milp_outlier_reinsertion_aimms}
\begin{alignat}{4}
\min_{\v{y},\v{z}}~~& \rho \sum_{i \in \mc{O}} z_i & & \\
\st~~& \sum_{j \in \mc{C}_i} d_{ij}y_{ij} + \epsilon \leq d_{ik} + M_{ik} z_k  && \qquad \forall (i,k) \in \mc{IK} \label{eq:bigM_constraint_reinsertion_improved} \\
    & \sum_{j \in \mc{C}_i} y_{ij} = 1 - z_i && \qquad \forall i \in \mc{N}, j \in \mc{C}_i \label{eq:bigM_select_exactly_one_neighbor_3} \\
    & y_{ij} \leq 1 - z_j && \qquad \forall i \in \mc{N}, j \in \mc{C}_i \cap \mc{O} \\
    & y_{ij} \in \{0,1\} && \qquad \forall i \in \mc{N}, j \in \mc{C}_i \\
    & z_{i} \in \{0,1\} && \qquad \forall i \in \mc{O}
\end{alignat}
\end{subequations}


\end{document}